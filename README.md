## 💻 Large Language Models (LLMs) <br />
Learning Journey: Computer Vision

## 🔍 Description <br />
This repo is my personal journey of mastering essential LLMs models by: <br />
✅ Implemented each model from scratch with help from online references. <br />
✅ Documented key achievements, pros/cons, and use cases. <br />
✅ Compared results and shared insights.

## 📚 Models Covered <br />
Early / Deep NLP Research
- Word2Vec
- Seq2Seq

Transformer Architecture (Foundation)
- Transformer

Encoder-Only Models (Understanding / Pretraining)
- BERT
- T5

Decoder-Only Models (Generation)
- GPT
- GPT-2

Scaling & Alignment / Instruction-Following
- GPT-3
- InstructGPT
- GPT-4

Democratized / Frontier Models
- LLaMA
- DeepSeek

<!--
## 📂 Repo Structure

```
├── models/
|  |── AlexNet          # AlexNet implementation
|  |── VGG              # VGG implementation
|  |── ...               
├── notes/          
|  |── AlexNet          # AlexNet notes (theory, results, references)
|  |── VGG              # VGG notes (theory, results, references)
|  |── ...               
├── datasets/           # Used datasets
└── README.md           # Roadmap (this file)
-->
