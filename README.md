## ğŸ’» Large Language Models (LLMs) <br />
Learning Journey: Computer Vision

## ğŸ” Description <br />
This repo is my personal journey of mastering essential LLMs models by: <br />
âœ… Implemented each model from scratch with help from online references. <br />
âœ… Documented key achievements, pros/cons, and use cases. <br />
âœ… Compared results and shared insights.

## ğŸ“š Models Covered <br />
Early / Deep NLP Research
- Word2Vec (TBD)
- Seq2Seq (TBD)

Transformer Architecture (Foundation)
- Transformer (TBD)

Encoder-Only Models (Understanding / Pretraining)
- BERT (TBD)
- T5 (TBD)

Decoder-Only Models (Generation)
- GPT (TBD)
- GPT-2 (TBD)

Scaling & Alignment / Instruction-Following
- GPT-3 (TBD)
- InstructGPT (TBD)
- GPT-4 (TBD)

Democratized / Frontier Models
- LLaMA (TBD)
- DeepSeek (TBD)

<!--
## ğŸ“‚ Repo Structure

```
â”œâ”€â”€ models/
|  |â”€â”€ AlexNet          # AlexNet implementation
|  |â”€â”€ VGG              # VGG implementation
|  |â”€â”€ ...               
â”œâ”€â”€ notes/          
|  |â”€â”€ AlexNet          # AlexNet notes (theory, results, references)
|  |â”€â”€ VGG              # VGG notes (theory, results, references)
|  |â”€â”€ ...               
â”œâ”€â”€ datasets/           # Used datasets
â””â”€â”€ README.md           # Roadmap (this file)
-->
