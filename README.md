## 💻 Large Language Models (LLMs) <br />
Learning Journey: Computer Vision

## 🔍 Description <br />
This repo is my personal journey of mastering essential LLMs models by: <br />
✅ Implemented each model from scratch with help from online references. <br />
✅ Documented key achievements, pros/cons, and use cases. <br />
✅ Compared results and shared insights.

## 📚 Models Covered <br />
Early / Deep NLP Research
- Word2Vec (TBD)
- Seq2Seq (TBD)

Transformer Architecture (Foundation)
- Transformer (TBD)

Encoder-Only Models (Understanding / Pretraining)
- BERT (TBD)
- T5 (TBD)

Decoder-Only Models (Generation)
- GPT (TBD)
- GPT-2 (TBD)

Scaling & Alignment / Instruction-Following
- GPT-3 (TBD)
- InstructGPT (TBD)
- GPT-4 (TBD)

Democratized / Frontier Models
- LLaMA (TBD)
- DeepSeek (TBD)

<!--
## 📂 Repo Structure

```
├── models/
|  |── AlexNet          # AlexNet implementation
|  |── VGG              # VGG implementation
|  |── ...               
├── notes/          
|  |── AlexNet          # AlexNet notes (theory, results, references)
|  |── VGG              # VGG notes (theory, results, references)
|  |── ...               
├── datasets/           # Used datasets
└── README.md           # Roadmap (this file)
-->
